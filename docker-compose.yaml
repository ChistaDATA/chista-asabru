version: "3.8"
services:
  clickhouse-1:
    image: clickhouse/clickhouse-server:23.11
    environment:
      - CLICKHOUSE_DB=default
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
      - CLICKHOUSE_PASSWORD=password
    ports:
      - "9363:9363"
      - "9000:9000"
      - "9440:9440"
      - "8123:8123"
      - "8443:8443"

    volumes:
      - ./external/clickhouse-1/config.xml:/etc/clickhouse-server/config.xml
      - ./external/clickhouse-1/init-db.sql:/docker-entrypoint-initdb.d/init.sql
        # Uncomment the below lines to setup TLS for wire level protocol
        # Reference : https://www.bytebase.com/blog/how-to-configure-clickhouse-ssl-connection/
#       - /Users/midhundarvin/software/openssl/trusted/rootCA.pem:/etc/clickhouse-server/ca.pem
#       - /Users/midhundarvin/software/openssl/trusted/root.localhost.pem:/etc/clickhouse-server/server.pem
#       - /Users/midhundarvin/software/openssl/trusted/device.key:/etc/clickhouse-server/server.key
#       - /Users/midhundarvin/software/openssl/dhparam.pem:/etc/clickhouse-server/dhparam.pem
#       - /Users/midhundarvin/software/openssl/config.xml:/etc/clickhouse-server/config.xml
    networks:
      - backend

  postgres-1:
    image: postgres:14.4
    command:
      - -c
      - shared_preload_libraries=pg_stat_statements
    #    command: >
    #      -c ssl=on
    #      -c ssl_cert_file=/var/lib/postgresql/server.crt
    #      -c ssl_key_file=/var/lib/postgresql/server.key
    ports:
      - "5432:5432"
      - "2345:2345"
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-123456}
      PGDATA: /var/lib/postgresql/postgres-1/data/pgdata
    volumes:
      - source: ./external/postgres
        target: /docker-entrypoint-initdb.d
        type: bind
        read_only: true
      - source: pg_data
        target: /var/lib/postgresql/postgres-1/data
        type: volume
      - /Users/midhundarvin/certs/postgres/server.crt:/var/lib/postgresql/server.crt:ro
      - /Users/midhundarvin/certs/postgres/server.key:/var/lib/postgresql/server.key:ro
    networks:
      - backend

  postgres-exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:latest
    command: >
      --config.file="/tmp/postgres_exporter.yml"
    ports:
      - "9187:9187"
    volumes:
      - ./external/postgres-exporter/postgres_exporter.yml:/tmp/postgres_exporter.yml
    environment:
      DATA_SOURCE_NAME: "postgresql://postgres:123456@postgres-1:5432/postgres?sslmode=disable"
    networks:
      - backend

  clickhouse-2:
    image: clickhouse/clickhouse-server:23.11
    ports:
#      - "9000:9000"
#      - "9440:9440"
      - "8124:8123"
#      - "8443:8443"
    environment:
      - CLICKHOUSE_DB=fluentbit
      - CLICKHOUSE_USER=fluentbit
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
      - CLICKHOUSE_PASSWORD=password
    volumes:
      - "./external/clickhouse-2/init-db.sql:/docker-entrypoint-initdb.d/init.sql"
    networks:
      - backend

  fluent-bit:
    image: fluent/fluent-bit:latest
    restart: always
    volumes:
      - ./external/fluent-bit/functions.lua:/fluent-bit/scripts/functions.lua
      - ./external/fluent-bit/fluent-bit.conf:/fluent-bit/etc/fluent-bit.conf
      - ./external/fluent-bit/parser.conf:/fluent-bit/etc/parser.conf
    ports:
      - "5170:5170"
    depends_on:
      - clickhouse-1
    networks:
      - backend
#
#  parseable:
#    image: parseable/parseable:edge
#    command: ["parseable", "local-store"]
#    ports:
#      - "8000:8000"
#    environment:
#      - P_S3_URL=https://minio.parseable.io:9000
#      - P_S3_ACCESS_KEY=minioadmin
#      - P_S3_SECRET_KEY=minioadmin
#      - P_S3_REGION=us-east-1
#      - P_S3_BUCKET=parseable
#      - P_LOCAL_STORAGE=/tmp/data
#      - P_USERNAME=parseable
#      - P_PASSWORD=parseable
#      - P_STAGING_DIR=/parseable/staging
#      - P_LOCAL_MODE=true
#    volumes:
#      - source: parseable_data
#        target: /parseable
#        type: volume
#    networks:
#      - backend

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
    ports:
      - "9090:9090"
    restart: unless-stopped
    volumes:
      - ./external/prometheus:/etc/prometheus
      - prom_data:/prometheus
    networks:
      - backend

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      SNOWFLAKE_ACCOUNT: ${SNOWFLAKE_EXPORTER_ACCOUNT:-}
      SNOWFLAKE_USERNAME: ${SNOWFLAKE_EXPORTER_USERNAME:-}
      SNOWFLAKE_PASSWORD: ${SNOWFLAKE_EXPORTER_PASSWORD:-}
      SNOWFLAKE_ROLE: ${SNOWFLAKE_EXPORTER_ROLE:-}
      SNOWFLAKE_WAREHOUSE: ${SNOWFLAKE_EXPORTER_WAREHOUSE:-}
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: grafana
      GF_INSTALL_PLUGINS: grafana-clickhouse-datasource
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Admin
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: michelin-snowflake-datasource
    volumes:
      - source: ./external/grafana/provisioning
        target: /etc/grafana/provisioning
        type: bind
      - source: ./external/grafana/dashboards
        target: /var/lib/grafana/dashboards
        type: bind
      - source: ./external/grafana/plugins
        target: /var/lib/grafana/plugins
        type: bind
    networks:
      - backend
#
#  snowflake-exporter:
#    build:
#      context: ./external/snowflake-exporter
#    ports:
#      - "9975:9975"
#    environment:
#      SNOWFLAKE_EXPORTER_ACCOUNT: ${SNOWFLAKE_EXPORTER_ACCOUNT:-}
#      SNOWFLAKE_EXPORTER_USERNAME: ${SNOWFLAKE_EXPORTER_USERNAME:-}
#      SNOWFLAKE_EXPORTER_PASSWORD: ${SNOWFLAKE_EXPORTER_PASSWORD:-}
#      SNOWFLAKE_EXPORTER_ROLE: ${SNOWFLAKE_EXPORTER_ROLE:-}
#      SNOWFLAKE_EXPORTER_WAREHOUSE: ${SNOWFLAKE_EXPORTER_WAREHOUSE:-}
#      SNOWFLAKE_EXPORTER_WEB_TELEMETRY_PATH: ${SNOWFLAKE_EXPORTER_WEB_TELEMETRY_PATH:-}
#    networks:
#      - backend

  mongo:
    image: mongo
    ports:
      - 27017:27017
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: example

  mongo-express:
    image: mongo-express
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_BASICAUTH_USERNAME: root
      ME_CONFIG_BASICAUTH_PASSWORD: example
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/

#  intercepting-proxy:
#    # platform: linux/amd64
#    build:
#      context: .
#      dockerfile: ./Dockerfile
#    ports:
#      - "8080:8080"
#      - "9100:9100"
#      - "9110:9110"
#      - "9120:9120"
#      - "9130:9130"
#      - "9140:9140"
#      - "9150:9150"
#      - "9160:9160"
#      - "9170:9170"
#    depends_on:
#      - clickhouse-1
#      - fluent-bit
##      - parseable
#    environment:
#      # CONFIG_FILE_URL: https://pastebin.com/raw/2Ts9aeN7 # Thread per client version
#      # CONFIG_FILE_URL: https://pastebin.com/raw/72vCDJvm # libuv version
#      CONFIG_FILE_PATH: /bin/config.xml
#      LOGGER_TYPE: NET
#      NETWORK_LOGGER_HOST: fluent-bit
#      NETWORK_LOGGER_PORT: 5170
#      SSL_CERT_FILE_PATH: /bin/server.pem
#      SSL_KEY_FILE_PATH: /bin/server.key
#      SSL_VERIFY_CERT: false
#    # network_mode: "host"
#    volumes:
#      - ./docker-proxy-config.xml:/bin/config.xml
#      - /Users/midhundarvin/software/openssl/server.pem:/bin/server.pem
#      - /Users/midhundarvin/software/openssl/server.key:/bin/server.key
#    links:
#      - "clickhouse-1:clickhouse-1"
##      - "postgres-1:postgres-1"
#      - "fluent-bit:fluent-bit"
#    #      - "serving-proxy-1:cluster-1"
#    #      - "serving-proxy-2:cluster-2"
#    #      - "serving-proxy-3:cluster-3"
#    #      - "serving-proxy-4:cluster-4"
#    networks:
#      - backend

#  zookeeper:
#    image: 'bitnami/zookeeper:latest'
#    ports:
#      - '2181:2181'
#    environment:
#      ALLOW_ANONYMOUS_LOGIN: yes
#    networks:
#      - backend

#  zk-monitor:
#    build:
#      context: ./lib/zk-cluster-monitor-client
#      dockerfile: ./Dockerfile
#    environment:
#      MODE: monitor
#      ZK_HOST: zookeeper:2181
#      ZK_ROOT_NODE: /cluster1
#      ASABRU_API_URL: http://proxy:8080/updateService
#    links:
#      - "zookeeper:zookeeper"
#      - "intercepting-proxy:proxy"
#    depends_on:
#      - zookeeper
#      - intercepting-proxy
#    networks:
#      - backend
#
#  zk-client-1:
#    build:
#      context: ./lib/zk-cluster-monitor-client
#      dockerfile: ./Dockerfile
#    environment:
#      MODE: client
#      ZK_HOST: zookeeper:2181
#      ZK_ROOT_NODE: /cluster1
#    links:
#      - "zookeeper:zookeeper"
#    depends_on:
#      - zk-monitor
#      - intercepting-proxy
#    networks:
#      - backend
#
#  serving-proxy-1:
#    build:
#      context: .
#      dockerfile: ./Dockerfile
#    expose:
#      - "9100"
#      - "9110"
#    ports:
#      - "9111:9110"
#    environment:
#      CONFIG_FILE_URL: https://pastebin.com/raw/NSufsj00
#      CONFIG_FILE_PATH: /tmp/config.xml
#    networks:
#      - backend
#
#  serving-proxy-2:
#    build:
#      context: .
#      dockerfile: ./Dockerfile
#    expose:
#      - "9100"
#      - "9110"
#    ports:
#      - "9112:9110"
#    environment:
#      CONFIG_FILE_URL: https://pastebin.com/raw/NSufsj00
#      CONFIG_FILE_PATH: /tmp/config.xml
#    networks:
#      - backend
#
#  serving-proxy-3:
#    build:
#      context: .
#      dockerfile: ./Dockerfile
#    expose:
#      - "9100"
#      - "9110"
#    ports:
#      - "9113:9110"
#    environment:
#      CONFIG_FILE_URL: https://pastebin.com/raw/NSufsj00
#      CONFIG_FILE_PATH: /tmp/config.xml
#    networks:
#      - backend
#
#  serving-proxy-4:
#    build:
#      context: .
#      dockerfile: ./Dockerfile
#    expose:
#      - "9100"
#      - "9110"
#    ports:
#      - "9114:9110"
#    environment:
#      CONFIG_FILE_URL: https://pastebin.com/raw/NSufsj00
#      CONFIG_FILE_PATH: /tmp/config.xml
#    networks:
#      - backend

#  mysql-1:
#    image: mysql/mysql-server
#    # NOTE: use of "mysql_native_password" is not recommended: https://dev.mysql.com/doc/refman/8.0/en/upgrading-from-previous-series.html#upgrade-caching-sha2-password
#    # (this is just an example, not intended to be a production configuration)
#    command: [ "mysqld",
#               "--character-set-server=utf8mb4",
#               "--collation-server=utf8mb4_unicode_ci",
#               "--require_secure_transport=ON",
#               "--ssl-ca=/etc/certs/root-ca.pem",
#               "--ssl-cert=/etc/certs/server-cert.pem",
#               "--ssl-key=/etc/certs/server-key.pem",
#               "--default_authentication_plugin=mysql_native_password" ]
#    restart: always
#    environment:
#      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-123456}
#      MYSQL_ROOT_HOST: "%"
#    volumes:
#      - type: volume
#        source: mysql_data
#        target: /var/lib/mysql
#      - type: bind
#        source: /Users/midhundarvin/certs/mysql
#        target: /etc/certs/
#    ports:
#      - "3306:3306"
#    networks:
#      - backend

volumes:
  pg_data:
  mysql_data:
  parseable_data:
  prom_data:
  grafana_storage:
networks:
  backend:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1400
